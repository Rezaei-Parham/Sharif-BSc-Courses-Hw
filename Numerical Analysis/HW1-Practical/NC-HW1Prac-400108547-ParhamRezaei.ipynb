{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTe7A85B_rrj"
      },
      "source": [
        "<p style=\"color:red;\">Name: Parham Rezaei</P>\n",
        "<p style=\"color:green;\">STD Number: 400108547</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7pT60pu_rrn"
      },
      "source": [
        "colab stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dID8zbms_rrn",
        "outputId": "95ac8ca9-4d72-4891-a321-1edb6cc3271f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-s23h9h2c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-s23h9h2c\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4294 sha256=25f6e5c75abdac596c71049874c4e1165d6a24a514a044e6b20db04e66e4fa5d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eic3807l/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX1_NNxu_rrp"
      },
      "source": [
        "# Problem 1 (بخش الف)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I implemented it using C for matrix size 1024*1024.\n",
        "first I allocated the space for the pointers and the array itself then I filled it randomly with float numbers.</b>\n",
        "Afterwards, I called the multiply function which performs the multiplication algorithm by iterating through all rows and collumns. Lastly, I freed the used memory."
      ],
      "metadata": {
        "id": "0_MEDJVLIdMN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKrZP6Bw_rrp",
        "outputId": "f8b95153-8654-4570-d7e5-7f959e394932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Matrix Multiplication Size 1024 took 9.248623 seconds\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "\n",
        "void multiply(float **p1, float **p2, float **p3, int m);\n",
        "int main(){\n",
        "    int m = 1024;\n",
        "    int fpsize = m * sizeof(float *);\n",
        "    int fsize = m * sizeof(float);\n",
        "    // first matrix\n",
        "    float **p1 = (float **)malloc(fpsize);\n",
        "    // second matrix\n",
        "    float **p2 = (float **)malloc(fpsize);\n",
        "    // result matrix\n",
        "    float **p3 = (float **)malloc(fpsize);\n",
        "    // allocating each row of the matrix\n",
        "    for (int i = 0; i < m; i++){\n",
        "        p1[i] = (float *)malloc(fsize);\n",
        "        p2[i] = (float *)malloc(fsize);\n",
        "        p3[i] = (float *)calloc(m,sizeof(float)); // calloc so no need to initialize to 0\n",
        "    }\n",
        "    // fill matrices randomly\n",
        "    for(int i = 0; i < m; i++){\n",
        "        for(int j = 0; j < m; j++){\n",
        "            p1[i][j] = (float)rand() / RAND_MAX;\n",
        "            p2[i][j] = (float)rand() / RAND_MAX;\n",
        "        }\n",
        "    }\n",
        "    // calculating the time\n",
        "    clock_t start,end;\n",
        "    start = clock();\n",
        "    // doing the multiplication\n",
        "    multiply(p1, p2, p3, m);\n",
        "    end = clock();\n",
        "    // calculate the time it took\n",
        "    double time = ((double)(end-start))/CLOCKS_PER_SEC;\n",
        "    printf(\"CPU Matrix Multiplication Size %d took %f seconds\\n\", m, time);\n",
        "\n",
        "    // free the allocated memory\n",
        "    for(int i = 0; i < m; i++){\n",
        "        free(p1[i]);\n",
        "        free(p2[i]);\n",
        "        free(p3[i]);\n",
        "    }\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "void multiply(float **p1, float **p2, float **p3, int m){\n",
        "    for(int i = 0; i < m; i++){\n",
        "        for(int j = 0; j < m; j++){\n",
        "            for(int l = 0; l < m; l++){\n",
        "                p3[i][j] += p1[i][l] * p2[l][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see that it takes more than any other code in this hw"
      ],
      "metadata": {
        "id": "X4KtmRL9JCXs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I2Uu4f8_rrq"
      },
      "source": [
        "# Problem 2 (بخش ب)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all I allocate the cpu memory as before. I use malloc for cuda too (with cudaMalloc) and allocate the same space there too which is stored in variable size. I also fill the matrices randomly and copy them to device from host.<br>\n",
        "Then, I call the multiply kernel which first finds the corresponding row and column for the thread and if it is in the bound iterates through memory values and calculates the result.<br>\n",
        "I also have a cpu function that checks the results after copying back to host with a simple accurate cpu algorithm to make sure the results are within a correct interval."
      ],
      "metadata": {
        "id": "4BsLu40yJJXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXtbmwC7_rrq",
        "outputId": "ffa68169-2f03-459d-8eb4-70beb278bbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication GPU Size 1024 takes 0.006643 seconds\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    // defining row and column based on current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(row < m && col < m){ // check for being inside the bounds\n",
        "        float sum = 0;\n",
        "        for (int i=0; i<m; i++){\n",
        "            sum+= a[row*m+i] * b[i*m+col]; //dot product\n",
        "        }\n",
        "        c[row*m+col] = sum; //assign the value to the result\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = 1024;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    // allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    // initialize matrices\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    // allocate memory for device\n",
        "    float *dp1, *dp2, *dp3;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // launch kernel\n",
        "    int thr = 32; //threads in each axis\n",
        "    int blc = m / thr; //blocks to make all matrix size\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin,end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    // call kernel\n",
        "    multiply<<<blocks, threads>>>(dp1, dp2, dp3, m);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication GPU Size %d takes %f seconds\", m,time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> much less than the cpu one"
      ],
      "metadata": {
        "id": "NjTNqMDhJ7sf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aceIW6UR_rrr"
      },
      "source": [
        "here I implement the 10240 one, but won't check the result becasue of getting too long on cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5IrbaZG_rrr",
        "outputId": "474fede2-b37d-4dff-d322-d57f3659d170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication GPU Size 10240 takes 3.765575 seconds\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    // defining row and column based on current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(row < m && col < m){ // check for being inside the bounds\n",
        "        float sum = 0;\n",
        "        for (int i=0; i<m; i++){\n",
        "            sum+= a[row*m+i] * b[i*m+col]; //dot product\n",
        "        }\n",
        "        c[row*m+col] = sum; //assign the value to the result\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = 10240;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    // allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    // initialize matrices\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    // allocate memory for device\n",
        "    float *dp1, *dp2, *dp3;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // launch kernel\n",
        "    int thr = 32; //threads in each axis\n",
        "    int blc = m / thr; //blocks to make all matrix size\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin,end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    // call kernel\n",
        "    multiply<<<blocks, threads>>>(dp1, dp2, dp3, m);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication GPU Size %d takes %f seconds\", m,time/1000);\n",
        "\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> clearly more than the 1024 size. Still way faster than cpu"
      ],
      "metadata": {
        "id": "BQpolYSnKBhJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_xxgzu__rrr"
      },
      "source": [
        "# Problem 3 (بخش ج)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- This one was removed from the hw (announced in Telegram)"
      ],
      "metadata": {
        "id": "2GI2UZpwKOrl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like before, I implemented the process of using the kernel. Here I have two constant values of trsize and matsize. They are because of using the shared memory as it required me to use constant values.<br>\n",
        "we first load onto the shared memory and then calculate based on the indices of this memory. Access to shared memory which is common for a block is much quicker than accessing the global memory each time. Notice we still need to use the global memory while filling the shared memory."
      ],
      "metadata": {
        "id": "Lq9j1IE6KYue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here is a one without sharing, I use 4 threads to make the results suitable for comparing."
      ],
      "metadata": {
        "id": "l-5ioBizLOgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    // defining row and column based on current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(row < m && col < m){ // check for being inside the bounds\n",
        "        float sum = 0;\n",
        "        for (int i=0; i<m; i++){\n",
        "            sum+= a[row*m+i] * b[i*m+col]; //dot product\n",
        "        }\n",
        "        c[row*m+col] = sum; //assign the value to the result\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = 1024;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    // allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    // initialize matrices\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    // allocate memory for device\n",
        "    float *dp1, *dp2, *dp3;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // launch kernel\n",
        "    int thr = 4; //threads in each axis\n",
        "    int blc = m / thr; //blocks to make all matrix size\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin,end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    // call kernel\n",
        "    multiply<<<blocks, threads>>>(dp1, dp2, dp3, m);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication GPU Size %d takes %f seconds\", m,time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ih8PZUFWLOCO",
        "outputId": "d31deb1f-f09b-40c4-8273-eb8e7b251f16"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication GPU Size 1024 takes 0.028759 seconds\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shared"
      ],
      "metadata": {
        "id": "-S4iMp_zLPBD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "398ajBYR_rrr",
        "outputId": "43696c86-2d59-4293-8dae-8e4cb818e1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication GPU Size 1024 takes 0.048847 seconds\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "// the values in __shared__ should be constant so I define them here\n",
        "#define trsize 4\n",
        "#define matsize 1024\n",
        "//CUDA kernel\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    // row and column index for current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    // shared memory\n",
        "    __shared__ float s_a[trsize][matsize];\n",
        "    __shared__ float s_b[matsize][trsize];\n",
        "\n",
        "    //load data to shared memory\n",
        "    for (int i=0; i<m/trsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x + i*trsize] = a[row*m + threadIdx.x + i*trsize];\n",
        "        s_b[threadIdx.y + i*trsize][threadIdx.x] = b[(threadIdx.y + i*trsize)*m + col];\n",
        "    }\n",
        "    // make sure all data is loaded\n",
        "    __syncthreads();\n",
        "\n",
        "    float tmp = 0.0f;\n",
        "    for (int k=0;k<m;k++){\n",
        "        tmp += s_a[threadIdx.y][k] * s_b[k][threadIdx.x]; // dot product\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = tmp; // assign to result\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    // allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    // initialize matrices\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    // allocate memory for device\n",
        "    float *dp1, *dp2, *dp3;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // launch kernel\n",
        "    int thr = trsize; //threads in each axis\n",
        "    int blc = m / thr; //blocks to make all matrix size\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin,end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    // call kernel\n",
        "    multiply<<<blocks, threads>>>(dp1, dp2, dp3, m);\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication GPU Size %d takes %f seconds\", m,time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfwp_pJm_rrs"
      },
      "source": [
        "# Problem 4 (بخش د)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is use tiles. I divide the matrix into several tiles and calculate the result on each of them separately. Using this sort of synchronize accesses to the shared memory in the phases caused by using tiles we see a bit of improvement. Also we have an edge by using tiles as they reduce the on-chip memory."
      ],
      "metadata": {
        "id": "Pn-wReGTLh4i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The implementation is similar as before. The main difference is in the kernel which we iterate through the tiles and load from memory and calculate result partially on each iteration."
      ],
      "metadata": {
        "id": "QD7OaITAMRsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1024"
      ],
      "metadata": {
        "id": "bwHMmmMqMgFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsyObecd_rrt",
        "outputId": "d4926918-8592-43d1-af6e-2b1ddd1e6a7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time of multiplication with gpu: 0.030304\n",
            "\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define matsize 1024\n",
        "#define tsize 4\n",
        "//CUDA kernel\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "    __shared__ float s_a[tsize][tsize];\n",
        "    __shared__ float s_b[tsize][tsize];\n",
        "\n",
        "    for(int i=0;i < m/tsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x] = a[row*m + threadIdx.x + i*tsize];\n",
        "        s_b[threadIdx.y][threadIdx.x] = b[m*(threadIdx.y+i*tsize)+col];\n",
        "        __syncthreads();\n",
        "        for(int p=0;p<tsize;p++){\n",
        "            sum += s_a[threadIdx.y][p]*s_b[p][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = sum;\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    float *dev1, *dev2, *dev3;\n",
        "    cudaMalloc(&dev1, size);\n",
        "    cudaMalloc(&dev2, size);\n",
        "    cudaMalloc(&dev3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dev1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = tsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    multiply<<<blocks, threads>>>(dev1, dev2, dev3, m);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dev3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"time of multiplication with gpu: %f\\n\", time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dev1);\n",
        "    cudaFree(dev2);\n",
        "    cudaFree(dev3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "testing larger thread size. still 1024 matrix size"
      ],
      "metadata": {
        "id": "nwMiyBNBMqNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define matsize 1024\n",
        "#define tsize 32\n",
        "//CUDA kernel\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "    __shared__ float s_a[tsize][tsize];\n",
        "    __shared__ float s_b[tsize][tsize];\n",
        "\n",
        "    for(int i=0;i < m/tsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x] = a[row*m + threadIdx.x + i*tsize];\n",
        "        s_b[threadIdx.y][threadIdx.x] = b[m*(threadIdx.y+i*tsize)+col];\n",
        "        __syncthreads();\n",
        "        for(int p=0;p<tsize;p++){\n",
        "            sum += s_a[threadIdx.y][p]*s_b[p][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = sum;\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    float *dev1, *dev2, *dev3;\n",
        "    cudaMalloc(&dev1, size);\n",
        "    cudaMalloc(&dev2, size);\n",
        "    cudaMalloc(&dev3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dev1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = tsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    multiply<<<blocks, threads>>>(dev1, dev2, dev3, m);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dev3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"time of multiplication with gpu: %f\\n\", time/1000);\n",
        "    // checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dev1);\n",
        "    cudaFree(dev2);\n",
        "    cudaFree(dev3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fQDl6f7Ml1Q",
        "outputId": "3f637603-31a4-460b-9625-48d11f565571"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time of multiplication with gpu: 0.005266\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see much improvement in comparison to previous methods"
      ],
      "metadata": {
        "id": "tVmmuYNTMuqA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv1tSHos_rrt"
      },
      "source": [
        "10240 without checking the result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define matsize 10240\n",
        "#define tsize 4\n",
        "//CUDA kernel\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "    __shared__ float s_a[tsize][tsize];\n",
        "    __shared__ float s_b[tsize][tsize];\n",
        "\n",
        "    for(int i=0;i < m/tsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x] = a[row*m + threadIdx.x + i*tsize];\n",
        "        s_b[threadIdx.y][threadIdx.x] = b[m*(threadIdx.y+i*tsize)+col];\n",
        "        __syncthreads();\n",
        "        for(int p=0;p<tsize;p++){\n",
        "            sum += s_a[threadIdx.y][p]*s_b[p][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = sum;\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    float *dev1, *dev2, *dev3;\n",
        "    cudaMalloc(&dev1, size);\n",
        "    cudaMalloc(&dev2, size);\n",
        "    cudaMalloc(&dev3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dev1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = tsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    multiply<<<blocks, threads>>>(dev1, dev2, dev3, m);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dev3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"time of multiplication with gpu: %f\\n\", time/1000);\n",
        "    // checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dev1);\n",
        "    cudaFree(dev2);\n",
        "    cudaFree(dev3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T4HEisoEBSa",
        "outputId": "759f7cc8-9dd2-4ec2-a4aa-f586002db254"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time of multiplication with gpu: 16.387831\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phuZdjys_rru"
      },
      "source": [
        "making it faster by using more thread size"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define matsize 10240\n",
        "#define tsize 32\n",
        "//CUDA kernel\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    float sum = 0.0f;\n",
        "    __shared__ float s_a[tsize][tsize];\n",
        "    __shared__ float s_b[tsize][tsize];\n",
        "\n",
        "    for(int i=0;i < m/tsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x] = a[row*m + threadIdx.x + i*tsize];\n",
        "        s_b[threadIdx.y][threadIdx.x] = b[m*(threadIdx.y+i*tsize)+col];\n",
        "        __syncthreads();\n",
        "        for(int p=0;p<tsize;p++){\n",
        "            sum += s_a[threadIdx.y][p]*s_b[p][threadIdx.x];\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = sum;\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "    float *dev1, *dev2, *dev3;\n",
        "    cudaMalloc(&dev1, size);\n",
        "    cudaMalloc(&dev2, size);\n",
        "    cudaMalloc(&dev3, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dev1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = tsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "    multiply<<<blocks, threads>>>(dev1, dev2, dev3, m);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, stop);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dev3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"time of multiplication with gpu: %f\\n\", time/1000);\n",
        "    // checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dev1);\n",
        "    cudaFree(dev2);\n",
        "    cudaFree(dev3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCB5T2O_EEK3",
        "outputId": "f5bde5c5-fa0e-484d-fc6b-f291298b945c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time of multiplication with gpu: 2.585407\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here too. Using the same thread size and matrix size as before, we saw that it takes noticeably less time doing the same task by using tiling."
      ],
      "metadata": {
        "id": "nrIqimEyM0y3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZlevFLK_rru"
      },
      "source": [
        "# Part 5 (بخش ه)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz_nRk3m_rru"
      },
      "source": [
        "Even though we look at the matrices as 2d objects how they are stored in the memory is 1d. So accessing by rows and columns has a crucial impact on the total time required to execute tasks such as matrix multiplication.\n",
        "</br>\n",
        "reading by rows is reading continuously rather than reading separate points in memory that are some thing aroung one row (1024 or 10240) far apart.\n",
        "</br>\n",
        "When working with the first matrix, we read by rows so we have been using memory coalescing there. Therefore, as a way of making the multiplication faster we can thing of using the second matrix in the same way. What we have to do is to transpose it first and then use the same kind of indexing we acquired for the first matrix.\n",
        "</br>\n",
        "The problem is that transposing has a time cost itself. In the following code, I have implemented transposing by gpu and then multiplication. We see that as the transposing is time consuming, the overall result is not that much better."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "with shared memory"
      ],
      "metadata": {
        "id": "PR0d9bi5Pm8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyCJxYVJ_rru",
        "outputId": "b44ac9f5-dd53-48ea-dca2-43d5bfa79fbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication size 1024 time 0.055191\n",
            "\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "// sizes for shared memory\n",
        "#define trsize 4\n",
        "#define matsize 1024\n",
        "\n",
        "// kernel for transposing matrix\n",
        "__global__ void transpose(float *a, float* c){\n",
        "    // row and column for the current thread\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    c[col*matsize + row] = a[row*matsize + col];\n",
        "}\n",
        "\n",
        "//CUDA kernel for multiplication\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "     // row and column for the current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    // shared memory\n",
        "    __shared__ float s_a[trsize][matsize];\n",
        "    __shared__ float s_b[trsize][matsize];\n",
        "\n",
        "    //load data to shared memory\n",
        "    for (int i=0; i<m/trsize; i++){\n",
        "        s_a[threadIdx.y][threadIdx.x + i*trsize] = a[row*m + threadIdx.x + i*trsize];\n",
        "        s_b[threadIdx.x][threadIdx.y + i*trsize] = b[threadIdx.y + i*trsize+ m*col];\n",
        "    }\n",
        "    // making sure the data is loaded\n",
        "    __syncthreads();\n",
        "\n",
        "    float tmp = 0.0f;\n",
        "    for (int k=0;k<m;k++){\n",
        "        tmp += s_a[threadIdx.y][k] * s_b[threadIdx.x][k]; // dot product\n",
        "    }\n",
        "    if (col < m && row < m) c[m*row + col] = tmp; // assigning the result\n",
        "}\n",
        "\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *dp1, *dp2, *dp3, *dp4;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "    cudaMalloc(&dp4, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = trsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin, end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    transpose<<<blocks, threads>>>(dp2, dp4);\n",
        "    multiply<<<blocks, threads>>>(dp1, dp4, dp3, m);\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication size %d time %f\\n\",m, time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "without shared memory"
      ],
      "metadata": {
        "id": "srQJj42iPj5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "// sizes for shared memory\n",
        "#define trsize 4\n",
        "#define matsize 1024\n",
        "\n",
        "// kernel for transposing matrix\n",
        "__global__ void transpose(float *a, float* c){\n",
        "    // row and column for the current thread\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    c[col*matsize + row] = a[row*matsize + col];\n",
        "}\n",
        "\n",
        "//CUDA kernel for multiplication\n",
        "__global__ void multiply(const float *a, const float *b, float *c, int m){\n",
        "    // defining row and column based on current thread\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if(row < m && col < m){ // check for being inside the bounds\n",
        "        float sum = 0;\n",
        "        for (int i=0; i<m; i++){\n",
        "            sum+= a[row*m+i] * b[i+m*col]; //dot product\n",
        "        }\n",
        "        c[row*m+col] = sum; //assign the value to the result\n",
        "    }\n",
        "}\n",
        "\n",
        "void checkMultiplicationCorrect(float *p1, float *p2, float *p3, int m){\n",
        "    for (int i=0; i<m; i++){\n",
        "        for (int j=0; j<m; j++){\n",
        "            float val = 0;\n",
        "            for (int k=0; k<m; k++){\n",
        "                val += p1[i*m+k] * p2[k*m+j];\n",
        "            }\n",
        "            // check for being close enough\n",
        "            if (abs(p3[i*m+j] - val) > 0.0001){\n",
        "                printf(\"\\nwrong multiplication\\n\");\n",
        "                return;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    printf(\"\\ncorrect multiplication\\n\");\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int m = matsize;\n",
        "    size_t size = m * m * sizeof(float);\n",
        "\n",
        "    //allocate memory for host\n",
        "    float *p1 = (float *)malloc(size);\n",
        "    float *p2 = (float *)malloc(size);\n",
        "    float *p3 = (float *)malloc(size);\n",
        "\n",
        "    //initialize host memory\n",
        "    for (int i=0; i<m*m; i++){\n",
        "        p1[i] = (float)rand()/RAND_MAX;\n",
        "        p2[i] = (float)rand()/RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *dp1, *dp2, *dp3, *dp4;\n",
        "    cudaMalloc(&dp1, size);\n",
        "    cudaMalloc(&dp2, size);\n",
        "    cudaMalloc(&dp3, size);\n",
        "    cudaMalloc(&dp4, size);\n",
        "\n",
        "    // copy data to device from host\n",
        "    cudaMemcpy(dp1, p1, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dp2, p2, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    //launch kernel\n",
        "    int thr = trsize;\n",
        "    int blc = m / thr;\n",
        "    dim3 threads = dim3(thr, thr);\n",
        "    dim3 blocks = dim3(blc, blc);\n",
        "    // get the time of multiplication\n",
        "    cudaEvent_t begin, end;\n",
        "    cudaEventCreate(&begin);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(begin);\n",
        "    transpose<<<blocks, threads>>>(dp2, dp4);\n",
        "    multiply<<<blocks, threads>>>(dp1, dp4, dp3, m);\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, begin, end);\n",
        "    // copy back\n",
        "    cudaMemcpy(p3, dp3, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"Matrix Multiplication size %d time %f\\n\",m, time/1000);\n",
        "    checkMultiplicationCorrect(p1, p2, p3, m);\n",
        "    //free memory\n",
        "    cudaFree(dp1);\n",
        "    cudaFree(dp2);\n",
        "    cudaFree(dp3);\n",
        "    free(p1);\n",
        "    free(p2);\n",
        "    free(p3);\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLDcYg4zPNWC",
        "outputId": "ff964042-d035-4d57-86b8-735ef9dbc7a2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Multiplication size 1024 time 0.046143\n",
            "\n",
            "correct multiplication\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see that in this case, not using shared memory is a bit faster."
      ],
      "metadata": {
        "id": "v39w2WmwPq7O"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}